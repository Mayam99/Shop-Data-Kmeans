# -*- coding: utf-8 -*-
"""Shop Customer Data-Kmeans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/125r9RSa6R1pcfSrJi8A9jE4_OeDcs9Bq

#About the Shop Customer Data Dataset
###The Shop Customer Data dataset is commonly used for customer segmentation analysis. It contains data on customers of a retail shop, providing various attributes that can help in understanding customer behaviors and preferences.

* Customer ID: A unique identifier for each customer.
* Gender: The gender of the customer (Male/Female).
* Age: The age of the customer.
* Annual Income: The annual income of the customer.
* Spending Score: Score assigned by the shop, based on customer behavior and
  spending nature.
* Profession: The profession of the customer.
* Work Experience: The number of years of work experience of the customer.
* Family Size: The size of the customer's family.


#Source
You can find the Shop Customer Data dataset on the Kaggle website.

#Importing Necessary Libraries
We are required to importing the libraries so as to performing EDA. These include NumPy, Pandas, Matplotlib, and Seaborn.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd # Pandas is a powerful library for data manipulation and analysis.
import numpy as np # NumPy is a powerful tool for numerical computations in Python.
import matplotlib.pyplot as plt  # Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python
import seaborn as sns # Seaborn is a statistical data visualization library based on Matplotlib
# %matplotlib inline

"""#Loading the Dataset
###The line df = pd.read_csv starts the process of reading a CSV file into a pandas DataFrame.

###This allows for easy data manipulation and analysis using pandas functionalities.
"""

df = pd.read_csv("Customers.csv")

df.head() # Displays the first 5 rows of the Dataset

df.columns # Displays the names of the columns

df.shape # Displays the total count of the Rows and Columns of the dataset respectively.

df.describe(include='all')

df.info()

df.isnull().sum() # Displays the total count of the null valuesin the particular columns.

"""##Converting the data type
###The purpose of this code is to convert the 'Gender' column, which contains categorical data ('Male' and 'Female'), into numerical data (1 and 0).
"""

df['Gender'] = [1 if g == 'Male' else 0 for g in df['Gender']] # It transforms categorical data into numerical data

df # Checking if the changes are applied correctly

df.info()

df.dtypes

"""###The goal is to convert the 'Profession' column in the DataFrame df from categorical data into a format that can be easily used in machine learning models, specifically by using one-hot encoding.

###Also this ensures that the data type of the new columns is integer. The resulting columns will contain binary values (0 or 1)
"""

one_hot_encoded = pd.get_dummies(df['Profession'], prefix='Profession', dtype=int) # one-hot encoding

"""###The following code is to combine the original DataFrame df with the one-hot encoded DataFrame one_hot_encoded by adding the new one-hot encoded columns to the original DataFrame."""

df_encoded = pd.concat([df, one_hot_encoded], axis=1) #This is a function from the pandas library used to concatenate (combine) two or more DataFrames.

df_encoded # The resulting df_encoded DataFrame will contain all the original columns from df plus the new one-hot encoded columns from one_hot_encoded

"""## Dropping the Profession column as it is now not needed, as it contains strings"""

df_encoded = df_encoded.drop(['Profession'], axis=1) # Dropping the column
df_encoded.head() # Checking for the updated dataset

from sklearn.cluster import KMeans # This imports the KMeans class from the scikit-learn library, which is used for clustering data.

wcss = list() # wcss stands for "Within-Cluster Sum of Squares". It is a measure of the variance within each cluster. The goal is to minimize this value to ensure that the clusters are as tight as possible

for k in range(1, 15): #This loop iterates over a range of possible cluster numbers (from 1 to 14). The purpose is to calculate the WCSS for each number of clusters and determine the optimal number of clusters.
    k_means = KMeans(n_clusters=k) #  initializes the KMeans algorithm with k clusters.

    k_means.fit(df_encoded) #fits the KMeans algorithm to the data in df_encoded. This step involves assigning each data point to one of the k clusters and calculating the cluster centroids.

    wcss.append(k_means.inertia_) # retrieves the WCSS value for the current number of clusters k. This value is appended to the wcss list.

plt.plot(range(1, 15), wcss) # This line creates a line plot where the x-axis represents the number of clusters (k) and the y-axis represents the within-cluster sum of squares (WCSS) values.
plt.xlabel('number of k value') # This sets the label for the x-axis to "number of k value", indicating that it represents the different values of k (number of clusters).
plt.ylabel('wcss') # This sets the label for the y-axis to "wcss", indicating that it represents the WCSS values for each number of clusters.
plt.show() # This command displays the plot on the screen.

#Build Cluster algorithm
from sklearn.cluster import KMeans #Imports the KMeans class from the sci-kit-learn library, which is a popular machine-learning library in Python.
clusters_new = KMeans(4, random_state=42) #initializes the KMeans algorithm to create 4 clusters
clusters_new.fit(df_encoded) #applies the KMeans algorithm to the preprocessed data stored in df_encoded

#Assign clusters to the data set
df['clusterid_new'] = clusters_new.labels_

#these are standardized values.
clusters_new.cluster_centers_

df.head() #Checking the dataframe which includes the cluster id

df[df['clusterid_new']==3] # Checking for the specific cluster no 3 and data points in this cluster

df[df['clusterid_new']==0] # Checking for the specific cluster no 0 and data points in this cluster

df[df['clusterid_new']==1] ## Checking for the specific cluster no 1 and data points in this cluster

df[df['clusterid_new']==2]  # Checking for the specific cluster no 2 and data points in this cluster